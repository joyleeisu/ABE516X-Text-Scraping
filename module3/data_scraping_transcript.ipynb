{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## all imports\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import bs4 #this is beautiful soup\n",
    "\n",
    "from pandas import Series\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Data Scraping\n",
    "\n",
    "In this module, we'll focus on a data that has become extremely common on the Internet:  text data.  In principle, text is just another form of data, and text processing is just another part of \"data wrangling\".  While text is advantageous in that there is so much of it out there that can be used, it is challenging because it is \"unstructured.\"  It does not have the usual \"tabular\" characteristics, with fields.  Its also relatively \"dirty\", people misspell wrods and runwordstogether #unpredictably.\n",
    "\n",
    "Today, we'll talk about data scraping as it is associated with obtaining data from webpages. There is low level scraping where you parse the data out of the html code of the webpage. There also is scraping over APIs or Application Program Interface from websites who try to make your life a bit easier.  Its basically a language that helps you access features of a dataset, like text on a webpage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scraping:  HTML and APIs with Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. Web Scraping using Beautiful Soup\n",
    "\n",
    "Let's scrape some data using a fun library called Beautiful Soup. We'll create a CSV dataset of the a table on 311 reported Rodent Incidents around Boston.\n",
    "\n",
    "The website we are going to scrape is here.\n",
    "\n",
    "[County Housing Statistics](http://duspviz.mit.edu/_assets/data/county_housing_stats.html)\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "#### Importing Modules\n",
    "\n",
    "First import modules. **import requests** imports the requests module, and **import bs4** imports the Beautiful Soup library.\n",
    "\n",
    "FYI:  This tutorial is based on material developed by [DSUPviz](http://duspviz.mit.edu/tutorials/python-scraping/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing out Requests\n",
    "\n",
    "Requests will allow us to load a webpage into python so that we can parse it and manipulate it. Test this by running the following. Enter the following commands in terminal, and hit enter after entering each to run each of them.\n",
    "\n",
    "This allowed us to access all of the content from the source code of the webpage with Python, which we can now parse and extract data. It even printed to our console. Pretty cool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('http://duspviz.mit.edu/_assets/data/county_housing_stats.html')\n",
    "#print(response.text) # Print the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Testing out Beautiful Soup\n",
    "Our next big step is to test out Beautiful Soup. Let's talk about what this is...\n",
    "\n",
    "What is Beautiful Soup?\n",
    "Beautiful Soup is a Python library for parsing data out of HTML and XML files (aka webpages). It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. The major concept with Beautiful Soup is that it allows you to access elements of your page by following the CSS structures, such as grabbing all links, all headers, specific classes, or more. It is a powerful library. Once we grab elements, Python makes it easy to write the elements or relevant components of the elements into other files, such as a CSV, that can be stored in a database or opened in other software.\n",
    "\n",
    "The sample webpage we are using contains data on 'rodent incidents' in the greater Boston area. Let's use this file to explore the tree, and extract some data.\n",
    "\n",
    "Our first step is to *Make the Soup*\n",
    "\n",
    "First, we have to turn the website code into a Python object. We have already imported the Beautiful Soup library, so we can start calling some of the methods in the libary.  We will replace print response.text with the following command, and this turns the text into an Python object named soup.\n",
    "\n",
    "An important note: You need to specify the specific parser that Beautiful Soup uses to parse your text. This is done in the second argument of the BeautifulSoup function. The default is the built in Python parser, which we can call using html.parser\n",
    "\n",
    "You an also use lxml or html5lib. This is nicely described in the [documentation](http://www.crummy.com/software/BeautifulSoup/bs4/doc/). For our purposes, using the default is fine.\n",
    "\n",
    "Using the Beautiful Soup prettify() function, we can print the page to see the code printed in a readable and legible manner.\n",
    "\n",
    "At any point, if you need a reference, visit the Beautiful Soup [documentation](http://www.crummy.com/software/BeautifulSoup/bs4/doc/) for the official descriptions of functions. Prettify is a handy one to see our document in a clean fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(response.text, \"html.parser\")\n",
    "print(soup.prettify()) # Print the output using the 'prettify' function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigating the Data Structure\n",
    "\n",
    "With our data from the webpage nicely laid out, Beautiful Soup allows us to now navigate the data structure. We called our Beautiful Soup object soup, so we can run the Beautiful Soup functions on this object. Let's explore some ways to do this, try entering some of the following into your terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Access the title element\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the content of the title element\n",
    "soup.title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access data in the first 'p' tag\n",
    "soup.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access data in the first 'a' tag\n",
    "soup.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all links in the document (note it returns an array)\n",
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve elements by class equal to link using the attributes argument\n",
    "soup.findAll(attrs={'class' : 'link'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a specific link by ID\n",
    "soup.find(id=\"link3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access Data in the table (note it returns an array)\n",
    "soup.find_all('td')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Arrays\n",
    "The easiest way to access elements and then either write them to file or manipulate them is to save them as objects themselves. Note that our data is organzed into counties and several numbers. Let's save these to arrays, which are the easiest way to work with the data.\n",
    "\n",
    "The following gives us an array, we can work with the elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = soup.findAll(attrs={'class':'name'})\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = soup.findAll(attrs={'class':'name'})\n",
    "print(data[0].string)\n",
    "print(data[1].string)\n",
    "print(data[2].string)\n",
    "print(data[3].string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = soup.findAll(attrs={'class':'name'})\n",
    "for i in data:\n",
    "    print(i.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This array only gives us counties though, let's get all of the data elements from all classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = soup.findAll(attrs={'class':['name','fips','tot-pop','median-income','no-housing-units','med-home-val','owner-occupied','house-w-debt','house-wo-debt']})\n",
    "for i in data:\n",
    "    print(i.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all of our data that was nested in these tags saved to a Python array. Access the elements of the array by using data[x], where x is location in the array. In Python, arrays start at 0, so place 1 in a Python array is actually called by using a 0, and place 8 would be called by a 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0])\n",
    "print(data[1])\n",
    "print(data[0].string)\n",
    "print(data[1].string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "\n",
    "# load and get the website\n",
    "response = requests.get('http://duspviz.mit.edu/_assets/data/county_housing_stats.html')\n",
    "\n",
    "# create the soup\n",
    "soup = bs4.BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# find all the tags with class city or number\n",
    "data = soup.findAll(attrs={'class':['name','fips','tot-pop','median-income','no-housing-units','med-home-val','owner-occupied','house-w-debt','house-wo-debt']})\n",
    "\n",
    "# print 'data' to console\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see an array with our data elements nested within tags. This is what we want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('county_data.csv','w') # open new file, make sure path to your data file is correct\n",
    "\n",
    "p = 0 # initial place in array\n",
    "l = len(data)-1 # length of array minus one\n",
    "\n",
    "\n",
    "f.write(\"County, State, FIPS Code, Total Pop, Median Income ($), No. of Housing Units, Median Home Value ($), No. of Owner Occupied Housing Units, No. of Owner Occ. Housing Units with Debt, No. of Owner Occ. Housing Units without Debt\\n\") #write headers\n",
    "\n",
    "\n",
    "while p < l: # while place is less than length\n",
    "    f.write(data[p].string + \", \") # write county and add comma\n",
    "    p = p + 1 # increment\n",
    "    f.write(data[p].string + \", \") # write FIPS and add comma\n",
    "    p = p + 1 # increment\n",
    "    f.write(data[p].string + \", \") # write Total Pop and add comma\n",
    "    p = p + 1 # increment\n",
    "    f.write(data[p].string + \", \") # write Median Income and add comma\n",
    "    p = p + 1 # increment\n",
    "    f.write(data[p].string + \", \") # write No. of Housing Units and add comma\n",
    "    p = p + 1 # increment\n",
    "    f.write(data[p].string + \", \") # write Median Home Value and add comma\n",
    "    p = p + 1 # increment\n",
    "    f.write(data[p].string + \", \") # write No. of Owner Occupied Housing Units and add comma\n",
    "    p = p + 1 # increment\n",
    "    f.write(data[p].string + \", \") # write No. of Owner Occ. Housing Units with Debt and add comma\n",
    "    p = p + 1 # increment\n",
    "    f.write(data[p].string + \"\\n\") # write No. of Owner Occ. Housing Units without Debt and line break\n",
    "    p = p + 1 # increment\n",
    "\n",
    "    \n",
    "f.close() # close file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## JSON & Working with Web APIs\n",
    "\n",
    "Simply put, an Application Programming Interface is a standard that facilitates intercommunication between two or more computer programs.\n",
    "\n",
    "Web APIs are a more convenient way for programs to interact with websites. Many webistes now have a nice API that gives access to it's data in JSON format. JSON is a way to store data in an organized and logical manner. \n",
    "\n",
    "Some famous APIs are twitter, facebook, google, etc.  Sometimes you need to have special permission to use APIs and sometimes you can use them publicly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "a = {'a': 1, 'b':2}\n",
    "s = json.dumps(a)\n",
    "a2 = json.loads(s)\n",
    "a2['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a) # a dictionary\n",
    "print(s) # s is a string containing a in JSON encoding\n",
    "print(a2) # reading back the keys are now in unicode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## World Cup in JSON!\n",
    "\n",
    "There was an [API created for the World Cup](http://worldcup.sfg.io) that scraped current match results and output match data as JSON. Possible output includes events such as goals, substitutions, and cards. The [actual matches are listed here](http://worldcup.sfg.io/matches) in JSON. \n",
    "\n",
    "* Example from [Fernando Masanori](https://gist.github.com/fmasanori/1288160dad16cc473a53)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in getting data using an API is to use a GET request.  The GET request by default will return a text, but we can also tell it that we want that request back as a JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://worldcup.sfg.io/matches\"\n",
    "resp = requests.get(url)\n",
    "wc = resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of matches in 2019 World Cup: 52'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Number of matches in 2019 World Cup: %i\" % len(wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['venue', 'location', 'status', 'time', 'fifa_id', 'weather', 'attendance', 'officials', 'stage_name', 'home_team_country', 'away_team_country', 'datetime', 'winner', 'winner_code', 'home_team', 'away_team', 'home_team_events', 'away_team_events', 'home_team_statistics', 'away_team_statistics', 'last_event_update_at', 'last_score_update_at'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print keys in first match\n",
    "\n",
    "gameIndex = 0\n",
    "wc[gameIndex].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'France'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc[gameIndex]['winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc[gameIndex]['home_team']['goals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France 4 Korea Republic 0\n",
      "Germany 1 China PR 0\n",
      "Spain 3 South Africa 1\n",
      "Norway 3 Nigeria 0\n",
      "Brazil 3 Jamaica 0\n",
      "England 2 Scotland 1\n",
      "Australia 1 Italy 2\n",
      "Argentina 0 Japan 0\n",
      "Canada 1 Cameroon 0\n",
      "New Zealand 0 Netherlands 1\n",
      "Chile 0 Sweden 2\n",
      "USA 13 Thailand 0\n",
      "Nigeria 2 Korea Republic 0\n",
      "Germany 1 Spain 0\n",
      "France 2 Norway 1\n",
      "Australia 3 Brazil 2\n",
      "South Africa 0 China PR 1\n",
      "Japan 2 Scotland 1\n",
      "Jamaica 0 Italy 5\n",
      "England 1 Argentina 0\n",
      "Netherlands 3 Cameroon 1\n",
      "Canada 2 New Zealand 0\n",
      "Sweden 5 Thailand 1\n",
      "USA 3 Chile 0\n",
      "China PR 0 Spain 0\n",
      "South Africa 0 Germany 4\n",
      "Nigeria 0 France 1\n",
      "Korea Republic 1 Norway 2\n",
      "Italy 0 Brazil 1\n",
      "Jamaica 1 Australia 4\n",
      "Japan 0 England 2\n",
      "Scotland 3 Argentina 3\n",
      "Cameroon 2 New Zealand 1\n",
      "Netherlands 2 Canada 1\n",
      "Thailand 0 Chile 2\n",
      "Sweden 0 USA 2\n",
      "Germany 3 Nigeria 0\n",
      "Norway 1 Australia 1\n",
      "England 3 Cameroon 0\n",
      "France 2 Brazil 1\n",
      "Spain 1 USA 2\n",
      "Sweden 1 Canada 0\n",
      "Italy 2 China PR 0\n",
      "Netherlands 2 Japan 1\n",
      "Norway 0 England 3\n",
      "France 1 USA 2\n",
      "Italy 0 Netherlands 2\n",
      "Germany 1 Sweden 2\n",
      "England 1 USA 2\n",
      "Netherlands 1 Sweden 0\n",
      "England 1 Sweden 2\n",
      "USA 2 Netherlands 0\n"
     ]
    }
   ],
   "source": [
    "for elem in wc:\n",
    "    print(elem['home_team']['country'], elem['home_team']['goals'], elem['away_team']['country'], elem['away_team']['goals'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pandas DataFrame from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_number</th>\n",
       "      <th>location</th>\n",
       "      <th>datetime</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>winner</th>\n",
       "      <th>home_team_events</th>\n",
       "      <th>away_team_events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Parc des Princes</td>\n",
       "      <td>2019-06-07T19:00:00Z</td>\n",
       "      <td>{'country': 'France', 'code': 'FRA', 'goals': ...</td>\n",
       "      <td>{'country': 'Korea Republic', 'code': 'KOR', '...</td>\n",
       "      <td>France</td>\n",
       "      <td>[{'id': 1, 'type_of_event': 'goal', 'player': ...</td>\n",
       "      <td>[{'id': 6, 'type_of_event': 'substitution-out'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Roazhon Park</td>\n",
       "      <td>2019-06-08T13:00:00Z</td>\n",
       "      <td>{'country': 'Germany', 'code': 'GER', 'goals':...</td>\n",
       "      <td>{'country': 'China PR', 'code': 'CHN', 'goals'...</td>\n",
       "      <td>Germany</td>\n",
       "      <td>[{'id': 23, 'type_of_event': 'substitution-out...</td>\n",
       "      <td>[{'id': 19, 'type_of_event': 'yellow-card', 'p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Stade Océane</td>\n",
       "      <td>2019-06-08T16:00:00Z</td>\n",
       "      <td>{'country': 'Spain', 'code': 'ESP', 'goals': 3...</td>\n",
       "      <td>{'country': 'South Africa', 'code': 'RSA', 'go...</td>\n",
       "      <td>Spain</td>\n",
       "      <td>[{'id': 38, 'type_of_event': 'substitution-out...</td>\n",
       "      <td>[{'id': 37, 'type_of_event': 'goal', 'player':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Stade Auguste-Delaune</td>\n",
       "      <td>2019-06-08T19:00:00Z</td>\n",
       "      <td>{'country': 'Norway', 'code': 'NOR', 'goals': ...</td>\n",
       "      <td>{'country': 'Nigeria', 'code': 'NGA', 'goals':...</td>\n",
       "      <td>Norway</td>\n",
       "      <td>[{'id': 63, 'type_of_event': 'goal', 'player':...</td>\n",
       "      <td>[{'id': 61, 'type_of_event': 'yellow-card', 'p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Stade des Alpes</td>\n",
       "      <td>2019-06-09T13:30:00Z</td>\n",
       "      <td>{'country': 'Brazil', 'code': 'BRA', 'goals': ...</td>\n",
       "      <td>{'country': 'Jamaica', 'code': 'JAM', 'goals':...</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>[{'id': 98, 'type_of_event': 'goal', 'player':...</td>\n",
       "      <td>[{'id': 99, 'type_of_event': 'yellow-card', 'p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_number               location              datetime  \\\n",
       "0           NaN       Parc des Princes  2019-06-07T19:00:00Z   \n",
       "1           NaN           Roazhon Park  2019-06-08T13:00:00Z   \n",
       "2           NaN           Stade Océane  2019-06-08T16:00:00Z   \n",
       "3           NaN  Stade Auguste-Delaune  2019-06-08T19:00:00Z   \n",
       "4           NaN        Stade des Alpes  2019-06-09T13:30:00Z   \n",
       "\n",
       "                                           home_team  \\\n",
       "0  {'country': 'France', 'code': 'FRA', 'goals': ...   \n",
       "1  {'country': 'Germany', 'code': 'GER', 'goals':...   \n",
       "2  {'country': 'Spain', 'code': 'ESP', 'goals': 3...   \n",
       "3  {'country': 'Norway', 'code': 'NOR', 'goals': ...   \n",
       "4  {'country': 'Brazil', 'code': 'BRA', 'goals': ...   \n",
       "\n",
       "                                           away_team   winner  \\\n",
       "0  {'country': 'Korea Republic', 'code': 'KOR', '...   France   \n",
       "1  {'country': 'China PR', 'code': 'CHN', 'goals'...  Germany   \n",
       "2  {'country': 'South Africa', 'code': 'RSA', 'go...    Spain   \n",
       "3  {'country': 'Nigeria', 'code': 'NGA', 'goals':...   Norway   \n",
       "4  {'country': 'Jamaica', 'code': 'JAM', 'goals':...   Brazil   \n",
       "\n",
       "                                    home_team_events  \\\n",
       "0  [{'id': 1, 'type_of_event': 'goal', 'player': ...   \n",
       "1  [{'id': 23, 'type_of_event': 'substitution-out...   \n",
       "2  [{'id': 38, 'type_of_event': 'substitution-out...   \n",
       "3  [{'id': 63, 'type_of_event': 'goal', 'player':...   \n",
       "4  [{'id': 98, 'type_of_event': 'goal', 'player':...   \n",
       "\n",
       "                                    away_team_events  \n",
       "0  [{'id': 6, 'type_of_event': 'substitution-out'...  \n",
       "1  [{'id': 19, 'type_of_event': 'yellow-card', 'p...  \n",
       "2  [{'id': 37, 'type_of_event': 'goal', 'player':...  \n",
       "3  [{'id': 61, 'type_of_event': 'yellow-card', 'p...  \n",
       "4  [{'id': 99, 'type_of_event': 'yellow-card', 'p...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#pd.DataFrame(wc)\n",
    "data = pd.DataFrame(wc, columns = ['match_number', 'location', 'datetime', 'home_team', 'away_team', 'winner', 'home_team_events', 'away_team_events'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data['gameDate'] = pd.DatetimeIndex(data.datetime).date\n",
    "#data['gameTime'] = pd.DatetimeIndex(data.datetime).time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_number</th>\n",
       "      <th>location</th>\n",
       "      <th>datetime</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>winner</th>\n",
       "      <th>home_team_events</th>\n",
       "      <th>away_team_events</th>\n",
       "      <th>gameDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Parc des Princes</td>\n",
       "      <td>2019-06-07T19:00:00Z</td>\n",
       "      <td>{'country': 'France', 'code': 'FRA', 'goals': ...</td>\n",
       "      <td>{'country': 'Korea Republic', 'code': 'KOR', '...</td>\n",
       "      <td>France</td>\n",
       "      <td>[{'id': 1, 'type_of_event': 'goal', 'player': ...</td>\n",
       "      <td>[{'id': 6, 'type_of_event': 'substitution-out'...</td>\n",
       "      <td>2019-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Roazhon Park</td>\n",
       "      <td>2019-06-08T13:00:00Z</td>\n",
       "      <td>{'country': 'Germany', 'code': 'GER', 'goals':...</td>\n",
       "      <td>{'country': 'China PR', 'code': 'CHN', 'goals'...</td>\n",
       "      <td>Germany</td>\n",
       "      <td>[{'id': 23, 'type_of_event': 'substitution-out...</td>\n",
       "      <td>[{'id': 19, 'type_of_event': 'yellow-card', 'p...</td>\n",
       "      <td>2019-06-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Stade Océane</td>\n",
       "      <td>2019-06-08T16:00:00Z</td>\n",
       "      <td>{'country': 'Spain', 'code': 'ESP', 'goals': 3...</td>\n",
       "      <td>{'country': 'South Africa', 'code': 'RSA', 'go...</td>\n",
       "      <td>Spain</td>\n",
       "      <td>[{'id': 38, 'type_of_event': 'substitution-out...</td>\n",
       "      <td>[{'id': 37, 'type_of_event': 'goal', 'player':...</td>\n",
       "      <td>2019-06-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Stade Auguste-Delaune</td>\n",
       "      <td>2019-06-08T19:00:00Z</td>\n",
       "      <td>{'country': 'Norway', 'code': 'NOR', 'goals': ...</td>\n",
       "      <td>{'country': 'Nigeria', 'code': 'NGA', 'goals':...</td>\n",
       "      <td>Norway</td>\n",
       "      <td>[{'id': 63, 'type_of_event': 'goal', 'player':...</td>\n",
       "      <td>[{'id': 61, 'type_of_event': 'yellow-card', 'p...</td>\n",
       "      <td>2019-06-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Stade des Alpes</td>\n",
       "      <td>2019-06-09T13:30:00Z</td>\n",
       "      <td>{'country': 'Brazil', 'code': 'BRA', 'goals': ...</td>\n",
       "      <td>{'country': 'Jamaica', 'code': 'JAM', 'goals':...</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>[{'id': 98, 'type_of_event': 'goal', 'player':...</td>\n",
       "      <td>[{'id': 99, 'type_of_event': 'yellow-card', 'p...</td>\n",
       "      <td>2019-06-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_number               location              datetime  \\\n",
       "0           NaN       Parc des Princes  2019-06-07T19:00:00Z   \n",
       "1           NaN           Roazhon Park  2019-06-08T13:00:00Z   \n",
       "2           NaN           Stade Océane  2019-06-08T16:00:00Z   \n",
       "3           NaN  Stade Auguste-Delaune  2019-06-08T19:00:00Z   \n",
       "4           NaN        Stade des Alpes  2019-06-09T13:30:00Z   \n",
       "\n",
       "                                           home_team  \\\n",
       "0  {'country': 'France', 'code': 'FRA', 'goals': ...   \n",
       "1  {'country': 'Germany', 'code': 'GER', 'goals':...   \n",
       "2  {'country': 'Spain', 'code': 'ESP', 'goals': 3...   \n",
       "3  {'country': 'Norway', 'code': 'NOR', 'goals': ...   \n",
       "4  {'country': 'Brazil', 'code': 'BRA', 'goals': ...   \n",
       "\n",
       "                                           away_team   winner  \\\n",
       "0  {'country': 'Korea Republic', 'code': 'KOR', '...   France   \n",
       "1  {'country': 'China PR', 'code': 'CHN', 'goals'...  Germany   \n",
       "2  {'country': 'South Africa', 'code': 'RSA', 'go...    Spain   \n",
       "3  {'country': 'Nigeria', 'code': 'NGA', 'goals':...   Norway   \n",
       "4  {'country': 'Jamaica', 'code': 'JAM', 'goals':...   Brazil   \n",
       "\n",
       "                                    home_team_events  \\\n",
       "0  [{'id': 1, 'type_of_event': 'goal', 'player': ...   \n",
       "1  [{'id': 23, 'type_of_event': 'substitution-out...   \n",
       "2  [{'id': 38, 'type_of_event': 'substitution-out...   \n",
       "3  [{'id': 63, 'type_of_event': 'goal', 'player':...   \n",
       "4  [{'id': 98, 'type_of_event': 'goal', 'player':...   \n",
       "\n",
       "                                    away_team_events    gameDate  \n",
       "0  [{'id': 6, 'type_of_event': 'substitution-out'...  2019-06-07  \n",
       "1  [{'id': 19, 'type_of_event': 'yellow-card', 'p...  2019-06-08  \n",
       "2  [{'id': 37, 'type_of_event': 'goal', 'player':...  2019-06-08  \n",
       "3  [{'id': 61, 'type_of_event': 'yellow-card', 'p...  2019-06-08  \n",
       "4  [{'id': 99, 'type_of_event': 'yellow-card', 'p...  2019-06-09  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'categories': [{'categories': {'id': 1, 'name': 'Delivery'}},\n",
       "  {'categories': {'id': 2, 'name': 'Dine-out'}},\n",
       "  {'categories': {'id': 3, 'name': 'Nightlife'}},\n",
       "  {'categories': {'id': 4, 'name': 'Catching-up'}},\n",
       "  {'categories': {'id': 5, 'name': 'Takeaway'}},\n",
       "  {'categories': {'id': 6, 'name': 'Cafes'}},\n",
       "  {'categories': {'id': 7, 'name': 'Daily Menus'}},\n",
       "  {'categories': {'id': 8, 'name': 'Breakfast'}},\n",
       "  {'categories': {'id': 9, 'name': 'Lunch'}},\n",
       "  {'categories': {'id': 10, 'name': 'Dinner'}},\n",
       "  {'categories': {'id': 11, 'name': 'Pubs & Bars'}},\n",
       "  {'categories': {'id': 13, 'name': 'Pocket Friendly Delivery'}},\n",
       "  {'categories': {'id': 14, 'name': 'Clubs & Lounges'}}]}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://developers.zomato.com/api/v2.1/categories\"\n",
    "resp = requests.get(url, headers={'user-key': '1036cfe76c2b8d74c0a12334163d5c61'})\n",
    "wc = resp.json()\n",
    "wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
